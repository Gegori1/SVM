{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T02:05:07.949519Z",
     "start_time": "2021-04-09T02:05:07.863749Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVR_general_cvxopt:\n",
    "    \n",
    "    def __init__(self, C = 0.1, epsilon = 0.01, mu = 0.5, kernel = \"linear\", **kernel_param):\n",
    "        import numpy as np\n",
    "        from cvxopt import matrix, solvers, sparse\n",
    "        from sklearn.metrics.pairwise import pairwise_kernels\n",
    "        self.sparse = sparse\n",
    "        self.matrix = matrix\n",
    "        self.solvers = solvers\n",
    "        \n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.mu = mu\n",
    "         \n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.pairwise_kernels = pairwise_kernels\n",
    "        self.kernel_param = kernel_param\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # hyperparameters\n",
    "        C = self.C \n",
    "        epsilon =  self.epsilon\n",
    "        \n",
    "        kernel = self.kernel\n",
    "        pairwise_kernels = self.pairwise_kernels\n",
    "        \n",
    "        sparse = self.sparse \n",
    "        matrix = self.matrix \n",
    "        solvers = self.solvers \n",
    "        \n",
    "        # Useful parameters\n",
    "        ydim = y.shape[0]\n",
    "        onev = np.ones((ydim,1))\n",
    "        x0 = np.random.rand(ydim)\n",
    "        \n",
    "        def precompute(X, y, kernel):\n",
    "            # Prematrices for the optimizer\n",
    "            if kernel == \"linear\":\n",
    "                K = pairwise_kernels(X, X, metric = \"linear\")\n",
    "            else:\n",
    "                K = pairwise_kernels(X, X, metric = kernel, **self.kernel_param)\n",
    "            A = onev.T\n",
    "            b = 0.0\n",
    "            G = np.concatenate((np.identity(ydim), -np.identity(ydim)))\n",
    "            h_ = np.concatenate((100*C*np.ones(ydim)/y, 100*C*np.ones(ydim)/y)); \n",
    "            h = h_.reshape(-1, 1)\n",
    "\n",
    "            # Matrices for the optimizer\n",
    "            A = matrix(A)\n",
    "            b = matrix(b)\n",
    "            G = sparse(matrix(G))\n",
    "            h = matrix(h)\n",
    "            Ev = (epsilon*y.T)/100\n",
    "\n",
    "            # functions for the optimizer\n",
    "            def obj_func(x):\n",
    "                return 0.5* x.T @ K @ x + Ev @ (np.abs(x)) - y.T @ x\n",
    "\n",
    "            def obj_grad(x):\n",
    "                return x.T @ K + Ev @ (x/np.abs(x)) - y\n",
    "\n",
    "            def F(x = None, z = None):\n",
    "                if x is None: return 0, matrix(x0)\n",
    "                # objective dunction\n",
    "                val = matrix(obj_func(x))\n",
    "                # obj. func. gradient\n",
    "                Df = matrix(obj_grad(x))\n",
    "                if z is None: return val, Df\n",
    "                # hessian\n",
    "                H = matrix(z[0] * K)\n",
    "                return val, Df, H\n",
    "            \n",
    "            return {\"F\":F, \"A\":A, \"b\":b, \"G\":G, \"h\":h}\n",
    "        \n",
    "        # Solver\n",
    "        def solver(pre):\n",
    "            solvers.options['show_progress'] = False\n",
    "            sol = solvers.cp(F=pre[\"F\"], G=pre[\"G\"], h=pre[\"h\"], A=pre[\"A\"], b=pre[\"b\"])\n",
    "            return sol\n",
    "\n",
    "        def get_coefficients(sol, kernel):\n",
    "            # Support vectors\n",
    "            beta_1 = np.array(sol['x']).reshape(-1)\n",
    "            beta_n = np.abs(beta_1)/beta_1.max()\n",
    "            indx = beta_n > 1e-4\n",
    "            beta_sv = beta_1[indx]\n",
    "            x_sv = X[indx,:]\n",
    "            y_sv = y[indx]\n",
    "\n",
    "            # get w_phi and b\n",
    "            \n",
    "#             other = (kernel, self.kernel_param.values())\n",
    "#             k_sv = pairwise_kernels(x_sv, x_sv, *other)\n",
    "            if kernel == \"linear\":\n",
    "                k_sv = pairwise_kernels(x_sv, x_sv, metric = \"linear\")\n",
    "            else:\n",
    "                k_sv = pairwise_kernels(x_sv, x_sv, metric = kernel, **self.kernel_param)\n",
    "                \n",
    "\n",
    "            cons = np.where(beta_sv >= 0, 1 - epsilon/100, 1 + epsilon/100)\n",
    "\n",
    "            w_phi = beta_sv @ k_sv\n",
    "            b = np.mean((y_sv*cons - w_phi))\n",
    "            \n",
    "            # keep on memory for latter use\n",
    "            return beta_sv, x_sv, b\n",
    "            \n",
    "            \n",
    "        def run():\n",
    "            # get the pre/matrice\n",
    "            param1 = precompute(X, y, \"linear\")\n",
    "            param2 = precompute(X, y, kernel)\n",
    "            \n",
    "            # solve for the alphas\n",
    "            sol1 = solver(param1)\n",
    "            sol2 = solver(param2)\n",
    "            \n",
    "            #compute the coefficients\n",
    "            coef1 = get_coefficients(sol1, \"linear\")\n",
    "            coef2 = get_coefficients(sol2, kernel)\n",
    "            \n",
    "            # keep data in memory\n",
    "            self.coef1 = coef1; self.coef2 = coef2\n",
    "            return self\n",
    "        \n",
    "        return run()\n",
    "        \n",
    "    def predict(self, X_):\n",
    "        mu = self.mu\n",
    "         \n",
    "        beta_sv1, x_sv1, b1 = self.coef1\n",
    "        beta_sv2, x_sv2, b2 = self.coef2\n",
    "        \n",
    "        k_test1 = self.pairwise_kernels(x_sv1, X_, metric = \"linear\")\n",
    "        \n",
    "#         other = (self.kernel, self.kernel_param.values())\n",
    "#         k_test2 = self.pairwise_kernels(x_sv2, X_, *other)\n",
    "        k_test2 = self.pairwise_kernels(x_sv2, X_, metric = self.kernel, **self.kernel_param)\n",
    "\n",
    "        w_phi_test1 = beta_sv1 @ k_test1\n",
    "        w_phi_test2 = beta_sv2 @ k_test2\n",
    "        \n",
    "        f1 = w_phi_test1 + b1\n",
    "        f2 = w_phi_test2 + b2\n",
    "        \n",
    "        predict = mu*f1 + (1 - mu)*f2\n",
    "        return predict\n",
    "    \n",
    "    def coef_(self):\n",
    "        krn = self.kernel\n",
    "        beta_sv1, _, b1 = self.coef1\n",
    "        beta_sv2, _, b2 = self.coef2\n",
    "        return {'sv_linear':beta_sv1, \n",
    "                'b_linear':b1, \n",
    "                f'sv_{krn}1': beta_sv2,\n",
    "                f'b_{krn}1':b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeRun():\n",
    "    \"\"\"\n",
    "    IterativeRun:\n",
    "        Iterative and ordered SVR prediction and data storage for time series\n",
    "    \n",
    "    args: \n",
    "        - folder: folder inside Pickle folder to save the resulting predictions\n",
    "        - n: number of values to predict by iteration\n",
    "        - itr: number of iterations to run. From last to first. \n",
    "                (e.g: n = 2, itr = 10. y_test = -20_-18, ... -2_0)\n",
    "    \n",
    "    --Method--\n",
    "    \n",
    "        bas_optit: iterate, predict and store data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, folder, n = 1, itr = 1):\n",
    "        self.folder = folder\n",
    "        self.n = n\n",
    "        self.itr = itr\n",
    "        \n",
    "    def bas_optit(self, C, epsilon, gamma, mu): \n",
    "        \"\"\"\n",
    "        Iterate, predict and store prediction + error\n",
    "        \n",
    "        args: SVR Hyperparameters, and kernel weight (mu*linear_kernel + lmbda*rbf_kernel)\n",
    "            - C\n",
    "            - epsilon\n",
    "            - gamma\n",
    "            - mu\n",
    "        \"\"\"\n",
    "    #   n: test size, itr: # of iterations\n",
    "        n = self.n; itr = self.itr\n",
    "\n",
    "        cas = {}; mape = []; it = itr+1\n",
    "        yl = len(y)\n",
    "\n",
    "        # parameters\n",
    "        hyperparameters = {\n",
    "            'kernel' : \"rbf\",\n",
    "            'C' : C, \n",
    "            'epsilon' : epsilon, \n",
    "            'mu' : mu,\n",
    "            'gamma' : gamma, \n",
    "        }\n",
    "\n",
    "        cas[0] = hyperparameters\n",
    "\n",
    "        itera = np.flip(np.arange(1, it))\n",
    "        for i in itera:\n",
    "            j = i*n\n",
    "\n",
    "            # y, X split\n",
    "            X_train = X[:yl - j, :]; X_test = X[yl - j : yl - (j-n), :]\n",
    "            y_train = y[:yl - j];    y_test = y[yl - j : yl - (j-n)]\n",
    "\n",
    "            # test index\n",
    "            y_idx = y1.index[yl - j : yl - (j-n)]\n",
    "\n",
    "            # rescale X and y\n",
    "            scaler = MaxAbsScaler(); scaler.fit(X_train); \n",
    "            X_train = scaler.transform(X_train); X_test = scaler.transform(X_test)\n",
    "\n",
    "            scaler1 = MaxAbsScaler(); scaler1.fit(y_train)\n",
    "            y_train = scaler1.transform(y_train).reshape(-1)\n",
    "            y_test = y_test.reshape(-1)\n",
    "\n",
    "\n",
    "            # fit and predict\n",
    "            model = SVR_general_cvxopt(**hyperparameters).fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            # rescale y_test\n",
    "            y_pred = scaler1.inverse_transform(pred.reshape(-1, 1))\n",
    "\n",
    "            # keep data\n",
    "            yi = pd.DataFrame(y_test, index = y_idx, columns = [\"real\"])\n",
    "            yi[\"predict\"] = y_pred.reshape(-1)\n",
    "            yi[\"resta\"] = yi.real - yi.predict\n",
    "            yi[\"error\"] = (np.abs((yi.real - yi.predict)/yi.real))\n",
    "            cas[i] = yi\n",
    "            mape.append(yi.error.mean()*100)\n",
    "\n",
    "        # Store prediction\n",
    "        name_ = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")    \n",
    "        with open(f'Pickles//{self.folder}//{name_}', 'wb') as to_write:\n",
    "            pickle.dump(cas, to_write)\n",
    "\n",
    "        mape_mean = sum(mape)/itr\n",
    "\n",
    "        return -mape_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
