{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T20:36:00.533726Z",
     "start_time": "2021-03-12T20:36:00.393265Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVM_non_linear():\n",
    "    \"\"\" Classify binomial separable and non-separable data through linear and non_linear models.\n",
    "    \n",
    "        -- Parameter --\n",
    "            C: determines the number of points that contribute to creating the boundary. \n",
    "                (Default = 0.1)\n",
    "                The bigger the value of C, the lesser the points that the model will consider.\n",
    "        \n",
    "            kernel: name of the kernel that the model will use. Written in a format string \n",
    "                (Default = \"linear\"). \n",
    "        \n",
    "                acceptable parameters: \n",
    "                    \"additive_chi2\", \"chi2\", \"linear\", \"poly\", \n",
    "                    \"polynomial\", \"rbf\", \"laplacian\", \"sigmoid\", \"cosine\".\n",
    "        \n",
    "                for more information about individual kernels, visit the \n",
    "                sklearn pairwise metrics affinities and kernels user guide.\n",
    "\n",
    "        --Methods--\n",
    "            fit(X, y): Learn from the data. Returns self.\n",
    "\n",
    "            predict(X_test): Predicts new points. Returns X_test labels.\n",
    "\n",
    "            coef_(): Returns linear model w and b coefficients, or w, x, and b\n",
    "                for non_linear models\n",
    "\n",
    "            For more information about each method, visit specific documentations.\n",
    "            \n",
    "        --Example-- \n",
    "            ## Calls the classes in SVC_library_non_linear_kernel notebook\n",
    "            >>> %run SVC_library_non_linear_kernel.ipynb\n",
    "            ...\n",
    "            ## Initializes the object with custom parameters\n",
    "            >>> model = SVM_non_linear(C = 0.01, kernel = \"linear\")\n",
    "            ...\n",
    "            ## Uses the model to fit the data\n",
    "            >>> fitted_model = model.fit(X, y)\n",
    "            ...\n",
    "            ## Predicts with the given model\n",
    "            >>> y_prediction = fitted_model(X_test)\n",
    "            ...\n",
    "            ## e.g\n",
    "            >>> print(y_prediction)\n",
    "            np.array([1, 1, 1, 0, 0, 1, 0])\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C=0.1, kernel = \"linear\"):\n",
    "        from sklearn.metrics.pairwise import pairwise_kernels\n",
    "        from cvxopt import solvers, matrix\n",
    "        self.C = C\n",
    "        self.pairwise_kernels = pairwise_kernels\n",
    "        self.kernel = kernel\n",
    "        self.matrix = matrix\n",
    "        self.solvers = solvers\n",
    "        \n",
    "    # learn   \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # label preprocessing\n",
    "        a = np.unique(y); c = np.array([1, -1])\n",
    "        y = np.where(y == a[0], c[0], c[1])\n",
    "        \n",
    "        # pre_matrices\n",
    "        H = self.pairwise_kernels(X, X, metric = self.kernel); Y = np.outer(y, y)\n",
    "        Q = np.multiply(Y, H); q = -np.ones(y.shape)\n",
    "        A = np.array(y.reshape(1, -1), dtype = \"float64\"); b = 0.0\n",
    "        ydim = y.shape[0]\n",
    "        G = np.concatenate((np.identity(ydim), -np.identity(ydim)))\n",
    "        h_ = np.concatenate((self.C*np.ones(ydim), np.zeros(ydim))); h = h_.reshape(-1, 1)\n",
    "        \n",
    "        # matrices for the solver\n",
    "        matrix = self.matrix\n",
    "        Q = matrix(Q); q = matrix(q)\n",
    "        A = matrix(A); b = matrix(b)\n",
    "        G = matrix(G); h = matrix(h)\n",
    "        # solver\n",
    "        solvers = self.solvers\n",
    "        solvers.options['show_progress']=False\n",
    "        sol=solvers.qp(P=Q, q=q,G=G,h=h, A=A, b=b)\n",
    "        \n",
    "        # alphas threshhold and svs\n",
    "        alphas = np.array(sol['x']); indx = alphas > 1e-10 \n",
    "        alpha_sv = alphas[indx]\n",
    "        h_sv = H[indx[:,0],:]; y_sv = y[indx[:,0]]; x_sv = X[indx[:,0],:]\n",
    "\n",
    "        # a_k * y_k * K_k\n",
    "        w = (alpha_sv*y_sv).reshape(-1, 1)\n",
    "        ayk = np.multiply(w, h_sv)\n",
    "        # w and b\n",
    "        w_phi = np.sum(ayk, axis=0)\n",
    "        b = np.mean(y-w_phi)\n",
    "        \n",
    "        self.x_sv = x_sv\n",
    "        self.w = w; self.b = b; self.c = c; self.a = a\n",
    "        return self\n",
    "    \n",
    "    # predict\n",
    "    def predict(self, X_test):\n",
    "        # rename label variables\n",
    "        c = self.c; a = self.a\n",
    "        # rename coefficients\n",
    "        b = self.b; x_sv = self.x_sv\n",
    "        \n",
    "        # create new kernel\n",
    "        H = self.pairwise_kernels(x_sv, X_test, metric = self.kernel)\n",
    "        # multiply w and kernel\n",
    "        w_phi = np.sum(np.multiply(self.w, H), axis = 0)\n",
    "        \n",
    "        # predict new data\n",
    "        predict1 = np.sign(w_phi + b)\n",
    "        # rename to original labels\n",
    "        predict2 = np.where(predict1 == c[0], a[0], a[1])\n",
    "        return predict2\n",
    "    \n",
    "    # coefficient\n",
    "    def coef_(self):\n",
    "        if self.kernel == \"linear\":\n",
    "            w = self.w; x_sv = self.x_sv\n",
    "            w = np.sum(np.multiply(w, x_sv), axis = 0)\n",
    "            return w, self.b\n",
    "        else: \n",
    "            return self.w, self.x_sv,  self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T20:07:13.973252Z",
     "start_time": "2021-03-12T20:07:13.949400Z"
    }
   },
   "outputs": [],
   "source": [
    "class plott:\n",
    "    @staticmethod\n",
    "    def line(X, w, b):\n",
    "        xmin, xmax = min(X[:,0])-1, max(X[:,0]+1)\n",
    "        X_ = np.arange(xmin, xmax, 0.1)\n",
    "    \n",
    "        plt.plot(X_,(-w[0]*X_-b)/w[1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def scatter(X, y, m = \"o\"):\n",
    "        plt.scatter(X[:,0], X[:,1], c = y, marker = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:45:19.687983Z",
     "start_time": "2021-03-12T19:45:19.669033Z"
    }
   },
   "outputs": [],
   "source": [
    "class contour_plott:\n",
    "    @staticmethod\n",
    "    def color(X, y, kernel=\"linear\"):\n",
    "        h = .02\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "        \n",
    "        Z = SVM_non_linear(kernel = kernel).fit(X, y).predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
