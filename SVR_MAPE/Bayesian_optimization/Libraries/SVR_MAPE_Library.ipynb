{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T00:46:50.498573Z",
     "start_time": "2021-04-09T00:46:50.458293Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVR_general_cvxopt:\n",
    "    \n",
    "    def __init__(self, C = 0.1, epsilon = 0.01, mu = 0.5, lmbda = 0.5, kernel = \"linear\", **kernel_param):\n",
    "        import numpy as np\n",
    "        from cvxopt import matrix, solvers, sparse\n",
    "        from sklearn.metrics.pairwise import pairwise_kernels\n",
    "        from sklearn.utils import check_X_y, check_array\n",
    "        self.sparse = sparse\n",
    "        self.matrix = matrix\n",
    "        self.solvers = solvers\n",
    "        \n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.mu = mu\n",
    "        self.lmbda = lmbda\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.pairwise_kernels = pairwise_kernels\n",
    "        self.kernel_param = kernel_param\n",
    "        self.check_X_y = check_X_y\n",
    "        self.check_array = check_array\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = self.check_X_y(X, y)\n",
    "        # hyperparameters\n",
    "        C = self.C \n",
    "        epsilon =  self.epsilon\n",
    "        mu = self.mu\n",
    "        lmbda = self.lmbda\n",
    "        \n",
    "        kernel = self.kernel\n",
    "        pairwise_kernels = self.pairwise_kernels\n",
    "        \n",
    "        sparse = self.sparse \n",
    "        matrix = self.matrix \n",
    "        solvers = self.solvers \n",
    "        \n",
    "        # Useful parameters\n",
    "        ydim = y.shape[0]\n",
    "        onev = np.ones((ydim,1))\n",
    "        x0 = np.random.rand(ydim)\n",
    "        \n",
    "        # Prematrices for the optimizer\n",
    "        K = mu*pairwise_kernels(X, X, metric = \"linear\") + \\\n",
    "        lmbda*pairwise_kernels(X, X, metric = kernel, **self.kernel_param)\n",
    "        \n",
    "        A = onev.T\n",
    "        b = 0.0\n",
    "        G = np.concatenate((np.identity(ydim), -np.identity(ydim)))\n",
    "        h_ = np.concatenate((100*C*np.ones(ydim)/y, 100*C*np.ones(ydim)/y)); \n",
    "        h = h_.reshape(-1, 1)\n",
    "\n",
    "        # Matrices for the optimizer\n",
    "        A = matrix(A)\n",
    "        b = matrix(b)\n",
    "        G = sparse(matrix(G))\n",
    "        h = matrix(h)\n",
    "        Ev = (epsilon*y.T)/100\n",
    "        \n",
    "        # functions for the optimizer\n",
    "        def obj_func(x):\n",
    "            return 0.5* x.T @ K @ x + Ev @ (np.abs(x)) - y.T @ x\n",
    "\n",
    "        def obj_grad(x):\n",
    "            return x.T @ K + Ev @ (x/np.abs(x)) - y\n",
    "        \n",
    "        def F(x = None, z = None):\n",
    "            if x is None: return 0, matrix(x0)\n",
    "            # objective dunction\n",
    "            val = matrix(obj_func(x))\n",
    "            # obj. func. gradient\n",
    "            Df = matrix(obj_grad(x))\n",
    "            if z is None: return val, Df\n",
    "            # hessian\n",
    "            H = matrix(z[0] * K)\n",
    "            return val, Df, H\n",
    "        \n",
    "        # Solver\n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = solvers.cp(F=F, G=G, h=h, A=A, b=b)\n",
    "\n",
    "        # Support vectors\n",
    "        beta_1 = np.array(sol['x']).reshape(-1)\n",
    "        beta_n = np.abs(beta_1)/beta_1.max()\n",
    "        indx = beta_n > 1e-4\n",
    "        beta_sv = beta_1[indx]\n",
    "        x_sv = X[indx,:]\n",
    "        y_sv = y[indx]\n",
    "        \n",
    "        # get w_phi and b\n",
    "        k_sv = mu*pairwise_kernels(x_sv, x_sv, metric = \"linear\") + \\\n",
    "        lmbda*pairwise_kernels(x_sv, x_sv, metric = kernel, **self.kernel_param)\n",
    "        \n",
    "        cons = np.where(beta_sv >= 0, 1 - epsilon/100, 1 + epsilon/100)\n",
    "        \n",
    "        w_phi = beta_sv @ k_sv\n",
    "        b = np.mean((y_sv*cons - w_phi)); self.b = b\n",
    "        self.beta_sv = beta_sv; self.x_sv = x_sv\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_):\n",
    "        X_ = self.check_array(X_)\n",
    "        k_test = self.mu*self.pairwise_kernels(self.x_sv, X_, metric = \"linear\") + \\\n",
    "        self.lmbda*self.pairwise_kernels(self.x_sv, X_, metric = self.kernel, **self.kernel_param)\n",
    "\n",
    "        w_phi_test = self.beta_sv @ k_test\n",
    "        predict = w_phi_test + self.b\n",
    "        return predict\n",
    "    \n",
    "    def coef_(self):\n",
    "        return self.beta_sv, self.x_sv, self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T22:07:42.701047Z",
     "start_time": "2021-04-17T22:07:42.651997Z"
    }
   },
   "outputs": [],
   "source": [
    "class IterativeRun():\n",
    "    \"\"\"\n",
    "    IterativeRun:\n",
    "        Iterative and ordered SVR prediction and data storage for time series\n",
    "    \n",
    "    args: \n",
    "        - folder: folder inside Pickle folder to save the resulting predictions\n",
    "        - n: number of values to predict by iteration\n",
    "        - itr: number of iterations to run. From last to first. \n",
    "                (e.g: n = 2, itr = 10. y_test = -20_-18, ... -2_0)\n",
    "    \n",
    "    --Method--\n",
    "    \n",
    "        bas_optit: iterate, predict and store data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, folder, n = 1, itr = 1):\n",
    "        from pathlib import Path\n",
    "        import pickle\n",
    "        self.folder = folder\n",
    "        self.n = n\n",
    "        self.itr = itr\n",
    "        self.Path = Path\n",
    "        self.pickle = pickle\n",
    "        \n",
    "    def bas_optit(self, C, epsilon, gamma, mu, lmbda): \n",
    "        \"\"\"\n",
    "        Iterate, predict and store prediction + error\n",
    "        \n",
    "        args: SVR Hyperparameters, and kernel weight (mu*linear_kernel + lmbda*rbf_kernel)\n",
    "            - C\n",
    "            - epsilon\n",
    "            - gamma\n",
    "            - mu\n",
    "            - lmbda\n",
    "        \"\"\"\n",
    "        \n",
    "        Path = self.Path\n",
    "    #   n: test size, itr: # of iterations\n",
    "        n = self.n; itr = self.itr\n",
    "\n",
    "        cas = {}; mape = []; it = itr+1\n",
    "        yl = len(y)\n",
    "\n",
    "        # parameters\n",
    "        hyperparameters = {\n",
    "            'kernel' : \"rbf\",\n",
    "            'C' : C, \n",
    "            'epsilon' : epsilon, \n",
    "            'mu' : mu,\n",
    "            'lmbda' : lmbda,\n",
    "            'gamma' : gamma, \n",
    "        }\n",
    "\n",
    "        cas[0] = hyperparameters\n",
    "\n",
    "        itera = np.flip(np.arange(1, it))\n",
    "        for i in itera:\n",
    "            j = i*n\n",
    "\n",
    "            # y, X split\n",
    "            X_train = X[:yl - j, :]; X_test = X[yl - j : yl - (j-n), :]\n",
    "            y_train = y[:yl - j];    y_test = y[yl - j : yl - (j-n)]\n",
    "\n",
    "            # test index\n",
    "            y_idx = y1.index[yl - j : yl - (j-n)]\n",
    "\n",
    "            # rescale X and y\n",
    "            scaler = MaxAbsScaler(); scaler.fit(X_train); \n",
    "            X_train = scaler.transform(X_train); X_test = scaler.transform(X_test)\n",
    "\n",
    "            scaler1 = MaxAbsScaler(); scaler1.fit(y_train)\n",
    "            y_train = scaler1.transform(y_train).reshape(-1)\n",
    "            y_test = y_test.reshape(-1)\n",
    "\n",
    "\n",
    "            # fit and predict\n",
    "            model = SVR_general_cvxopt(**hyperparameters).fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            # rescale y_test\n",
    "            y_pred = scaler1.inverse_transform(pred.reshape(-1, 1))\n",
    "\n",
    "            # keep data\n",
    "            yi = pd.DataFrame(y_test, index = y_idx, columns = [\"real\"])\n",
    "            yi[\"predict\"] = y_pred.reshape(-1)\n",
    "            yi[\"resta\"] = yi.real - yi.predict\n",
    "            yi[\"error\"] = (np.abs((yi.real - yi.predict)/yi.real))\n",
    "            cas[i] = yi\n",
    "            mape.append(yi.error.mean()*100)\n",
    "\n",
    "        # Store prediction\n",
    "        name_ = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")  \n",
    "        path_ = Path().resolve().parent / \"Pickles\" / f\"{self.folder}\" / f\"{name_}\"\n",
    "        with open(path_, 'wb') as to_write:\n",
    "            self.pickle.dump(cas, to_write)\n",
    "\n",
    "        mape_mean = sum(mape)/itr\n",
    "\n",
    "        return -mape_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
